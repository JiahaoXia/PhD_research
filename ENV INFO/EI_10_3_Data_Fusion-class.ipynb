{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Fusion\n",
    "Developed by Roger Wang (rq.wang@rutgers.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's data fusion?\n",
    "Data fusion is the process of integrating multiple data sources to produce more consistent, accurate, and useful information than that provided by any individual data source.\n",
    "\n",
    "An introduction: https://www.youtube.com/watch?v=6qV3YjFppuc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are good at data fusion naturally\n",
    "Humans are always performing data fusion and very good at it.\n",
    "\n",
    "REALLY? Let me show you some examples.\n",
    "\n",
    "McGurk Effect: https://www.youtube.com/watch?v=PWGeUztTkRA\n",
    "\n",
    "Cocktail party effect: https://www.youtube.com/watch?v=mN--nV61gDo\n",
    "\n",
    "Now, let's learn what we can use mathmatics to do data fusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: \n",
    "\"Due to the rich characteristics of natural processes and environments, it is rare that a single acquisition method provides complete understanding thereof. Information about a phenomenon or a system of interest can be obtained from different types of instruments, measurement techniques, experimental setups, and other types of sources. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fusion is a challenging task for several reasons:\n",
    "1. the data are generated by very complex systems: biological, environmental, sociological, and psy- chological, to name a few, driven by numerous underlying processes that depend on a large number of variables to which we have no access. \n",
    "2. due to the augmented diversity, the number, type, and scope of new research questions that can be posed is potentially very large. \n",
    "3. working with heterogeneous data sets such that the respective advantages of each data set are maximally exploited, and drawbacks suppressed, is not an evident task. (Lahat et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a broader perspective, each data aquisition framework is a modelity, and the collection of the frameworks is called multimodel. Data assimilation can be treated as a multimodel of a modeling modelity and a data stream modelity.\n",
    "\n",
    "A key property of the multimodel is complementarity so that each modelity brings value (or information) to the multimodel to resolve the uncertainty. \"In mathematical terms, this added value is known as diversity. Diversity allows to reduce the number of degrees of freedom in the system by providing constraints that enhance uniqueness, interpretability, robustness, performance, and other desired properties, ... Diversity can be found in a broad range of scenarios, and plays a key role in a wide scope of mathematical and engineering studies.\" (Lahat et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Presentation:\n",
    "In general, we are interested in a system:\n",
    "\n",
    "$$ x=f(\\mathbf{z}),$$\n",
    "where $\\mathbf{z}$ is a series of contributing factors that determine the system state of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fusion types:\n",
    "There are two types of data fusion methods: model-driven and data-driven. When a forecasting model is unknown, too complicated to use, or rapidily changing, we have to use model-free methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "This time, we will focus on the global temperature reconstructed from various sources. They can be downloaded from https://www.ncdc.noaa.gov/paleo-search/study/10437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd\n",
    "#!mkdir ./tempData\n",
    "%cd ./tempData\n",
    "#!wget https://www1.ncdc.noaa.gov/pub/data/paleo/contributions_by_author/frank2010/ensembles-10yearsmth.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df = pd.read_csv('ensembles-10yearsmth.txt',delimiter='\\t')\n",
    "m, n = df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.plot(df['Year'],df.iloc[:,1:],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean']=df.iloc[:,1:].mean(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.plot(df['Year'],df.iloc[:,1:-2],'.',color='grey',alpha=0.1)\n",
    "fig=plt.plot(df['Year'],df['mean'],'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=df.iloc[:,1:n].describe().iloc[2,:]\n",
    "var.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var_mean1']=df.iloc[:,1:n]@np.reciprocal(var)/np.sum(np.reciprocal(var))\n",
    "fig=plt.plot(df['Year'],df.iloc[:,1:-2],'.',color='grey',alpha=0.1)\n",
    "fig=plt.plot(df['Year'],df['mean'],'white')\n",
    "fig=plt.plot(df['Year'],df['var_mean1'],'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# clean data\n",
    "df=df.dropna()\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "var=np.zeros(n-1)\n",
    "for i, c in enumerate(df.columns[1:n]):\n",
    "    model.fit(df['Year'][:,np.newaxis],df[c][:,np.newaxis])\n",
    "    yfit=model.predict(df['Year'][:,np.newaxis])\n",
    "    var[i]=np.var(df[c][:,np.newaxis]-yfit)\n",
    "\n",
    "plt.hist(var)\n",
    "plt.show()    \n",
    "\n",
    "df['var_mean2']=df.iloc[:,1:n]@np.reciprocal(var)/np.sum(np.reciprocal(var))\n",
    "# fig=plt.plot(df['Year'],df.iloc[:,1:-2],'.',color='grey',alpha=0.1)\n",
    "fig=plt.plot(df['Year'],df['mean'],'black',label='naive mean')\n",
    "fig=plt.plot(df['Year'],df['var_mean1'],'blue',label='weighted mean 1')    \n",
    "fig=plt.plot(df['Year'],df['var_mean2'],'red',label='weighted mean 2')    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge:\n",
    "Complete the following code to use polynomial regression (degree 2) to remove the trend, calculate the variance and conduct the weighted average with the new variance vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# poly = PolynomialFeatures(__, include_bias=False)\n",
    "\n",
    "var=np.zeros(n-1)\n",
    "for i, c in enumerate(df.____):\n",
    "    poly_model = make_pipeline(PolynomialFeatures(___),\n",
    "                           LinearRegression())               #\n",
    "    poly_model.fit(df[___][:,np.newaxis],df[___][:,np.newaxis])     # fitting the data\n",
    "    yfit=poly_model.predict(df[___][:,np.newaxis])              # making predictions\n",
    "    var[i]=np.var(df[___][:,np.newaxis]-yfit)                  # calculate variance\n",
    "\n",
    "plt.hist(var)\n",
    "plt.show()    \n",
    "\n",
    "df['var_mean3']=df.iloc[:,1:n]@np.reciprocal(var)/np.sum(np.reciprocal(var))    # normalization\n",
    "\n",
    "# fig=plt.plot(df['Year'],df.iloc[:,1:-2],'.',color='grey',alpha=0.1)\n",
    "fig=plt.plot(df['Year'],df['mean'],'black',label='naive mean')\n",
    "fig=plt.plot(df['Year'],df['var_mean1'],'blue',label='weighted mean 1')    \n",
    "fig=plt.plot(df['Year'],df['var_mean2'],'red',label='weighted mean 2')    \n",
    "fig=plt.plot(df['Year'],df['var_mean3'],'yellow',label='weighted mean 3')    \n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fusion using Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymf3\n",
    "import numpy as np\n",
    "\n",
    "data=df.iloc[:,1:n].to_numpy()\n",
    "\n",
    "# nmf_mdl = pymf3.semiNMF(data, num_bases=1)\n",
    "\n",
    "nmf_mdl = pymf3.semiNMF(data, num_bases=1)\n",
    "nmf_mdl.factorize(niter=1000)\n",
    "# plt.plot(nmf_mdl.W)\n",
    "# scalar=np.mean(np.mean(data))/np.mean(nmf_mdl.W)\n",
    "\n",
    "df['seminmf']=nmf_mdl.W\n",
    "# fig=plt.plot(df['Year'],df.iloc[:,1:-2],'.',color='grey',alpha=0.1)\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "fig=plt.plot(df['Year'],df['mean'],'black',label='naive mean')\n",
    "fig=plt.plot(df['Year'],df['var_mean1'],'blue',label='weighted mean 1')    \n",
    "fig=plt.plot(df['Year'],df['var_mean2'],'red',label='weighted mean 2')    \n",
    "fig=plt.plot(df['Year'],df['var_mean3'],'yellow',label='weighted mean 3')    \n",
    "fig=plt.plot(df['Year'],df['seminmf']*np.mean(nmf_mdl.H),'purple',label='semi-NMF')    \n",
    "# fig=plt.plot(df['Year'],df.iloc[:,1:3],'x',label='semi-NMF',alpha=0.5)    \n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
